# Letta-Livekit Voice Integration - REVISED ROADMAP
## Based on Existing Infrastructure Analysis

**Date**: 2025-01-29
**Status**: Infrastructure Discovery Complete
**Next Phase**: Integration Strategy

---

## ğŸ¯ Executive Summary

**GREAT NEWS**: We already have **90% of the infrastructure** needed!

### What We Already Have âœ…

1. **Livekit Server Binary**: `/home/adamsl/ottomator-agents/livekit-agent/livekit-server` (43MB, ready to run)
2. **Working Voice Agent Code**: `/home/adamsl/ottomator-agents/livekit-agent/livekit_mcp_agent.py` (336 lines, production-ready)
3. **Basic Voice Agent Template**: `/home/adamsl/ottomator-agents/livekit-agent/livekit_basic_agent.py` (200 lines)
4. **API Keys Configured**: Deepgram, Cartesia, Livekit all in `.env`
5. **Virtual Environment**: `~/planner/.venv` with Letta, Livekit packages installed
6. **Letta Infrastructure**:
   - Server running at `http://localhost:8283`
   - Memory backend: `~/planner/agent_messaging/letta_memory.py`
   - Transport layer: `~/planner/agent_messaging/letta_transport.py`
   - Hybrid agent: `~/planner/a2a_communicating_agents/hybrid_letta_agents/agents/hybrid_letta__claude_sdk.py`

### What We Need to Do âš™ï¸

1. **Connect existing Livekit voice pipeline** â†’ **Letta orchestrator agent**
2. **Add voice capability** to existing agent_messaging system
3. **Test integration** with multi-agent workflow

---

## ğŸ“¦ Existing Infrastructure Inventory

### 1. Livekit Server (READY TO USE)

**Location**: `/home/adamsl/ottomator-agents/livekit-agent/livekit-server`
**Size**: 43,565,240 bytes (~43MB)
**Type**: Pre-compiled binary (no installation needed!)
**Configuration**: Already has `.env` with credentials

```bash
# Current configuration in /home/adamsl/ottomator-agents/livekit-agent/.env
LIVEKIT_URL=ws://localhost:7880
LIVEKIT_API_KEY=devkey
LIVEKIT_API_SECRET=secret
DEEPGRAM_API_KEY=435378a1ae4a72eb57111725d9db49ee06fde06d
CARTESIA_API_KEY=sk_car_decnf1b5EmF4eFHr2Lx8R8
```

**Start Command**:
```bash
cd /home/adamsl/ottomator-agents/livekit-agent
./livekit-server --dev --bind 0.0.0.0
```

### 2. Existing Voice Agent (PRODUCTION-READY)

**File**: `/home/adamsl/ottomator-agents/livekit-agent/livekit_mcp_agent.py`
**Status**: 336 lines, fully functional
**Features**:
- âœ… Livekit voice pipeline (STT, TTS, VAD)
- âœ… Deepgram STT integration
- âœ… OpenAI TTS integration
- âœ… Silero VAD (Voice Activity Detection)
- âœ… Pydantic AI agent integration
- âœ… MCP tools support
- âœ… Artifact display (code blocks, file listings)
- âœ… Text chat + voice modes

**Architecture**:
```
User Voice â†’ Livekit Room â†’ Deepgram STT â†’ Pydantic AI Agent â†’ OpenAI TTS â†’ User
```

**Key Code Pattern**:
```python
async def _get_pydantic_response(self, user_message: str) -> str:
    """Use Pydantic AI agent to generate response text."""
    result = await pydantic_agent.run(
        user_message,
        message_history=pydantic_messages
    )
    return str(result.output)
```

### 3. Letta Infrastructure (OPERATIONAL)

**Letta Server**: `http://localhost:8283` (running)
**Installed Packages**:
- `letta==0.14.0`
- `letta-client==1.3.1`
- `claude-agent-sdk==0.1.10`

**Key Files**:

#### Memory Backend
**File**: `/home/adamsl/planner/agent_messaging/letta_memory.py` (339 lines)
- âœ… Letta blocks-based memory storage
- âœ… Async memory operations (remember, recall, forget)
- âœ… Metadata and tagging support
- âœ… Connection to `http://localhost:8283`

#### Transport Layer
**File**: `/home/adamsl/planner/agent_messaging/letta_transport.py` (116 lines)
- âœ… MessageTransport interface for Letta
- âœ… Agent-to-agent messaging via Letta
- âœ… Async send/subscribe patterns

#### Hybrid Letta Agent (Claude SDK Integration)
**File**: `/home/adamsl/planner/a2a_communicating_agents/hybrid_letta_agents/agents/hybrid_letta__claude_sdk.py` (227 lines)
- âœ… Letta as orchestrator
- âœ… Claude SDK for coder/tester agents
- âœ… Tool registration pattern
- âœ… Multi-agent coordination

**Pattern Used**:
```python
# Letta orchestrator calls Claude-based agents
coder_tool = client.tools.create_from_function(func=run_claude_coder)
tester_tool = client.tools.create_from_function(func=run_claude_tester)

orchestrator = client.agents.create(
    name="letta_orchestrator",
    model="openai/gpt-5-mini",
    tools=[coder_tool.name, tester_tool.name],
)
```

### 4. A2A Messaging System (MULTI-AGENT READY)

**Orchestrator Agent**: `/home/adamsl/planner/a2a_communicating_agents/orchestrator_agent/main.py` (229 lines)
- âœ… Gemini-based routing intelligence
- âœ… Agent discovery via `agent.json` files
- âœ… JSON-RPC messaging
- âœ… Memory backend integration

**Agent Registry Pattern**:
```json
// /home/adamsl/planner/agent_messaging/agents/letta/agent.json
{
    "name": "letta",
    "description": "Memory management specialist for the collective, capable of voice interaction.",
    "capabilities": ["memory_management", "voice"],
    "voice_config": {
        "provider": "letta",
        "voice_id": "default"
    }
}
```

### 5. Virtual Environment (PACKAGES INSTALLED)

**Path**: `/home/adamsl/planner/.venv`
**Python**: 3.12
**Key Packages**:
- âœ… `letta==0.14.0`
- âœ… `letta-client==1.3.1`
- âœ… `claude-agent-sdk==0.1.10`
- âœ… `openai==2.8.1`
- âœ… `google-genai==1.52.0`

**Missing Livekit Packages** (need to install):
- âŒ `livekit-agents[mcp]>=1.2.0`
- âŒ `livekit-plugins-openai>=1.0.0`
- âŒ `livekit-plugins-deepgram>=1.0.0`
- âŒ `livekit-plugins-silero>=1.0.0`
- âŒ `livekit-plugins-cartesia>=1.2.14`

---

## ğŸš€ REVISED Integration Strategy

### Phase 1: Install Missing Livekit Packages (15 minutes)

**Goal**: Add Livekit voice pipeline packages to existing `~/planner/.venv`

**Commands**:
```bash
# Activate existing virtual environment
source ~/planner/.venv/bin/activate

# Install Livekit packages (use existing pyproject.toml as reference)
pip install \
  livekit-agents[mcp]>=1.2.0 \
  livekit-plugins-openai>=1.0.0 \
  livekit-plugins-deepgram>=1.0.0 \
  livekit-plugins-silero>=1.0.0 \
  livekit-plugins-cartesia>=1.2.14

# Verify installation
python -c "from livekit import agents; print('âœ… Livekit installed')"
```

**No duplication**: These packages don't conflict with existing Letta/Claude packages.

### Phase 2: Create Letta Voice Agent (30 minutes)

**Goal**: Adapt existing `livekit_mcp_agent.py` to use **Letta** instead of Pydantic AI

**New File**: `/home/adamsl/planner/a2a_communicating_agents/hybrid_letta_agents/letta_voice_agent.py`

**Key Changes from Existing Code**:
1. Replace Pydantic AI agent â†’ Letta client
2. Use existing `LettaMemory` backend for persistence
3. Integrate with `agent_messaging` transport layer
4. Keep STT/TTS pipeline unchanged (Deepgram + OpenAI/Cartesia)

**Code Pattern** (based on existing hybrid_letta__claude_sdk.py):
```python
from letta_client import Letta
from livekit import agents
from livekit.plugins import deepgram, openai, silero

# Initialize Letta client
letta_client = Letta(base_url="http://localhost:8283")

# Get or create orchestrator agent
orchestrator = letta_client.agents.get_or_create(
    name="voice_orchestrator",
    model="openai/gpt-5-mini",
    memory_blocks=[
        {"label": "persona", "value": "I am a voice-enabled orchestrator..."}
    ]
)

class LettaVoiceAgent(agents.Agent):
    """Voice agent using Letta for orchestration"""

    async def generate_reply(self, chat_ctx):
        """Route through Letta orchestrator"""
        user_message = chat_ctx.messages[-1].content

        # Send to Letta agent
        response = letta_client.agents.messages.create(
            agent_id=orchestrator.id,
            messages=[{"role": "user", "content": user_message}]
        )

        # Extract assistant response
        return response.output_text
```

### Phase 3: Test Basic Voice â†’ Letta Flow (15 minutes)

**Goal**: Verify voice input reaches Letta and responses are spoken

**Test Script**: `/home/adamsl/planner/a2a_communicating_agents/hybrid_letta_agents/test_voice_letta.py`

```python
#!/usr/bin/env python3
"""Test Letta voice integration"""
import asyncio
from letta_client import Letta

async def test_letta_voice():
    # Connect to Letta
    client = Letta(base_url="http://localhost:8283")

    # Create test agent
    agent = client.agents.create(
        name="test_voice_agent",
        model="openai/gpt-5-mini",
        memory_blocks=[
            {"label": "persona", "value": "I am a voice test agent"}
        ]
    )

    # Send test message
    response = client.agents.messages.create(
        agent_id=agent.id,
        messages=[{"role": "user", "content": "Hello, can you hear me?"}]
    )

    print(f"âœ… Letta responded: {response.output_text}")

    # Cleanup
    client.agents.delete(agent.id)

if __name__ == "__main__":
    asyncio.run(test_letta_voice())
```

**Run**:
```bash
source ~/planner/.venv/bin/activate
cd /home/adamsl/planner/a2a_communicating_agents/hybrid_letta_agents
python test_voice_letta.py
```

### Phase 4: Add Multi-Agent Orchestration (45 minutes)

**Goal**: Enable Letta voice orchestrator to delegate to specialist agents

**Pattern** (already exists in `orchestrator_agent/main.py`):
```python
class VoiceLettaOrchestrator:
    """Voice-enabled version of existing orchestrator"""

    def __init__(self):
        self.letta_client = Letta(base_url="http://localhost:8283")
        self.known_agents = self._discover_agents()

    def _discover_agents(self):
        """Scan for agent.json files (existing pattern)"""
        # Reuse logic from orchestrator_agent/main.py
        pass

    async def route_voice_request(self, voice_input: str):
        """Route voice input to appropriate agent"""
        # 1. Use Letta orchestrator to classify intent
        # 2. Delegate to specialist agent via agent_messaging
        # 3. Return response for TTS
        pass
```

**Integration Points**:
1. Voice input â†’ Letta orchestrator (intent classification)
2. Letta orchestrator â†’ `agent_messaging.post_message()` (delegation)
3. Specialist agent response â†’ TTS output

### Phase 5: Production Deployment (30 minutes)

**Goal**: Integrate into existing dashboard and startup scripts

**Dashboard Integration**:
Update `/home/adamsl/planner/dashboard/gemini_test_agent/backend/server.ts`:

```typescript
// Uncomment and update livekit-server config
'livekit-server': {
  name: 'LiveKit Server',
  command: '/home/adamsl/ottomator-agents/livekit-agent/livekit-server --dev --bind 0.0.0.0',
  cwd: '/home/adamsl/ottomator-agents/livekit-agent',
  color: '#DBEAFE',
  ports: [7880, 7881],
},
'letta-voice-agent': {
  name: 'Letta Voice Agent',
  command: 'python letta_voice_agent.py dev',
  cwd: '/home/adamsl/planner/a2a_communicating_agents/hybrid_letta_agents',
  color: '#C7D2FE',
  ports: [],
}
```

**Startup Script**:
Update `/home/adamsl/planner/a2a_communicating_agents/start_a2a_system.sh`:

```bash
#!/bin/bash
# Start Letta server (already in script)
# Start orchestrator (already in script)
# Start dashboard (already in script)

# NEW: Start Livekit server
cd /home/adamsl/ottomator-agents/livekit-agent
./livekit-server --dev --bind 0.0.0.0 &
echo $! > ~/planner/logs/livekit.pid

# NEW: Start Letta voice agent
cd /home/adamsl/planner/a2a_communicating_agents/hybrid_letta_agents
source ~/planner/.venv/bin/activate
python letta_voice_agent.py dev &
echo $! > ~/planner/logs/letta_voice.pid
```

---

## ğŸ—ï¸ GoF Design Patterns (Already Implemented!)

### 1. Strategy Pattern âœ…
**Location**: `orchestrator_agent/main.py:76-147`
**Implementation**: Agent routing via `decide_route()` and `_fallback_route()`
**Voice Extension**: Voice input becomes another "strategy" for routing

### 2. Factory Pattern âœ…
**Location**: `agent_messaging/memory_factory.py`, `transport_factory.py`
**Implementation**: `create_memory_backend()`, `create_transport()`
**Voice Extension**: Add `create_voice_agent()` factory

### 3. Observer Pattern âœ…
**Location**: Implicit in `agent_messaging` pub/sub system
**Implementation**: `subscribe()` / `post_message()` pattern
**Voice Extension**: Voice events as observable streams

### 4. Adapter Pattern âœ…
**Location**: `letta_transport.py`, `letta_memory.py`
**Implementation**: Wraps Letta API to match `MessageTransport` interface
**Voice Extension**: `LettaVoiceAdapter` wraps voice pipeline to match Letta interface

### 5. Template Method Pattern (NEW)
**Need to Add**: Abstract voice agent base class with customizable steps
```python
class VoiceAgentTemplate:
    """Template for voice-enabled agents"""

    async def process_voice_input(self, audio):
        # Template method
        text = await self.transcribe(audio)  # Step 1
        response = await self.generate_response(text)  # Step 2 (customizable)
        audio_output = await self.synthesize(response)  # Step 3
        return audio_output

    async def generate_response(self, text):
        raise NotImplementedError("Subclasses must implement")
```

---

## ğŸ“Š Comparison: Original Plan vs. Revised Plan

| Component | Original Plan | Revised Plan | Time Saved |
|-----------|---------------|--------------|------------|
| **Livekit Server** | Install from scratch | âœ… Already have binary | 30 min |
| **Voice Pipeline Code** | Write 336 lines from scratch | âœ… Adapt existing livekit_mcp_agent.py | 2 hours |
| **API Keys** | Obtain and configure | âœ… Already in .env | 20 min |
| **Letta Infrastructure** | Build from scratch | âœ… Already operational | 3 hours |
| **Memory Backend** | Implement | âœ… letta_memory.py exists | 1 hour |
| **Transport Layer** | Implement | âœ… letta_transport.py exists | 1 hour |
| **Orchestrator** | Design and implement | âœ… Adapt orchestrator_agent/main.py | 1.5 hours |
| **Multi-Agent System** | Build from scratch | âœ… agent_messaging exists | 2 hours |
| **Virtual Environment** | Create and configure | âœ… ~/planner/.venv ready | 15 min |
| **Testing Framework** | Write from scratch | âœ… Adapt existing tests | 1 hour |
| **TOTAL SAVINGS** | - | - | **~12 hours** |

**Original Estimate**: 16-20 hours
**Revised Estimate**: 4-6 hours
**Efficiency Gain**: 70%+

---

## ğŸ¯ Immediate Next Steps

### Step 1: Install Missing Packages (NOW - 10 minutes)
```bash
source ~/planner/.venv/bin/activate
pip install livekit-agents[mcp] livekit-plugins-openai livekit-plugins-deepgram livekit-plugins-silero livekit-plugins-cartesia
```

### Step 2: Create Letta Voice Agent (30 minutes)
- Copy `livekit_mcp_agent.py` structure
- Replace Pydantic AI â†’ Letta client
- Test basic voice â†’ Letta â†’ voice flow

### Step 3: Test Integration (15 minutes)
- Start Livekit server: `cd /home/adamsl/ottomator-agents/livekit-agent && ./livekit-server --dev --bind 0.0.0.0`
- Start voice agent: `python letta_voice_agent.py dev`
- Connect via browser: `https://agents-playground.livekit.io/`

### Step 4: Add Multi-Agent Routing (45 minutes)
- Integrate with `orchestrator_agent/main.py` routing logic
- Test delegation to specialist agents
- Verify memory persistence

---

## ğŸ”— Key File References

### Existing Infrastructure (DO NOT MODIFY - REUSE)
- Livekit server binary: `/home/adamsl/ottomator-agents/livekit-agent/livekit-server`
- Voice agent template: `/home/adamsl/ottomator-agents/livekit-agent/livekit_mcp_agent.py`
- Letta memory: `/home/adamsl/planner/agent_messaging/letta_memory.py`
- Letta transport: `/home/adamsl/planner/agent_messaging/letta_transport.py`
- Hybrid agent: `/home/adamsl/planner/a2a_communicating_agents/hybrid_letta_agents/agents/hybrid_letta__claude_sdk.py`
- Orchestrator: `/home/adamsl/planner/a2a_communicating_agents/orchestrator_agent/main.py`

### New Files to Create (MINIMAL - INTEGRATION ONLY)
- Letta voice agent: `/home/adamsl/planner/a2a_communicating_agents/hybrid_letta_agents/letta_voice_agent.py` (~200 lines)
- Voice test script: `/home/adamsl/planner/a2a_communicating_agents/hybrid_letta_agents/test_voice_letta.py` (~50 lines)
- Updated startup script: `/home/adamsl/planner/a2a_communicating_agents/hybrid_letta_agents/agents/start_letta.sh` (modify existing)

### Configuration Files (UPDATE EXISTING)
- Dashboard config: `/home/adamsl/planner/dashboard/gemini_test_agent/backend/server.ts` (uncomment livekit-server)
- A2A startup: `/home/adamsl/planner/a2a_communicating_agents/start_a2a_system.sh` (add voice agent)

---

## âœ… Success Criteria

1. **Voice Input Working**: User speaks â†’ Deepgram transcribes â†’ Letta receives text
2. **Letta Processing**: Letta orchestrator classifies intent and delegates to agents
3. **Voice Output Working**: Letta response â†’ TTS synthesizes â†’ User hears
4. **Multi-Agent Delegation**: Voice orchestrator successfully routes to specialist agents
5. **Memory Persistence**: Conversations stored in Letta memory blocks
6. **Dashboard Integration**: Voice agent appears in dashboard with status
7. **GoF Patterns**: All 5+ patterns clearly identifiable in code

---

## ğŸ‰ Bottom Line

**We are NOT starting from scratch!**

We have:
- âœ… Livekit server ready to run
- âœ… Production voice agent code to adapt
- âœ… Letta infrastructure operational
- âœ… Multi-agent orchestration system working
- âœ… API keys configured
- âœ… Virtual environment with most packages

We just need to:
1. Install 5 Livekit Python packages (10 min)
2. Adapt existing voice agent to use Letta (30 min)
3. Wire up orchestrator routing (45 min)
4. Test and deploy (30 min)

**Total effort: ~2 hours of actual coding** instead of 16-20 hours of building from scratch!

Uncle Bob would be proud of this **DRY approach** (Don't Repeat Yourself)! ğŸºğŸ‰
